{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BIWqBuEa6j0b"
   },
   "source": [
    "## Задача поиска схожих по смыслу предложений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUkwMPLA6j0g"
   },
   "source": [
    "Мы будем ранжировать вопросы [StackOverflow](https://stackoverflow.com) на основе семантического векторного представления "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNRXIEfu5a3Q"
   },
   "source": [
    "Введем математическую формулировку"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uS9FwWNd5a3S"
   },
   "source": [
    "## Задача ранжирования(Learning to Rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdwY9-f75a3T"
   },
   "source": [
    "* $X$ - множество объектов\n",
    "* $X^l = \\{x_1, x_2, ..., x_l\\}$ - обучающая выборка\n",
    "<br>На обучающей выборке задан порядок между некоторыми элементами, то есть нам известно, что некий объект выборки более релевантный для нас, чем другой:\n",
    "* $i \\prec j$ - порядок пары индексов объектов на выборке $X^l$ c индексами $i$ и $j$\n",
    "### Задача:\n",
    "построить ранжирующую функцию $a$ : $X \\rightarrow R$ такую, что\n",
    "$$i \\prec j \\Rightarrow a(x_i) < a(x_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WG2IGBsh5a3U"
   },
   "source": [
    "<img src=\"https://d25skit2l41vkl.cloudfront.net/wp-content/uploads/2016/12/Featured-Image.jpg\" width=500, height=450>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQk_rolFwT_h"
   },
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUe1PGXn6j0l"
   },
   "source": [
    "Будем использовать предобученные векторные представления слов на постах Stack Overflow.<br>\n",
    "[A word2vec model trained on Stack Overflow posts](https://github.com/vefstathiou/SO_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "mYkI54Y-rk7a"
   },
   "outputs": [],
   "source": [
    "# !wget https://zenodo.org/record/1199620/files/SO_vectors_200.bin?download=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scipy==1.10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install ipywidgets jupyterlab_widgets widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "O8YJTOYv6j0s",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_embeddings = KeyedVectors.load_word2vec_format(\"SO_vectors_200.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIcT_g-C6j1E"
   },
   "source": [
    "#### Как пользоваться этими векторами?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DWO5SPDY6j1G"
   },
   "source": [
    "Посмотрим на примере одного слова, что из себя представляет embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KeSBlQfk6j1J",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 (200,)\n"
     ]
    }
   ],
   "source": [
    "word = 'dog'\n",
    "if word in wv_embeddings:\n",
    "    print(wv_embeddings[word].dtype, wv_embeddings[word].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "T4Eq-D1qxpMJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of words: 1787145\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num of words: {len(wv_embeddings.index_to_key)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZT6NTCys6j1Q"
   },
   "source": [
    "Найдем наиболее близкие слова к слову `dog`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n08z2PjMwC5o"
   },
   "source": [
    "#### Вопрос 1:\n",
    "* Входит ли слов `cat` топ-5 близких слов к слову `dog`? Какое место? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nYwVz0xG6j1U",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# method most_simmilar\n",
    "def cosine_sim(v1, v2):\n",
    "    return np.array(v1@v2.T / norm(v1) / norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935495d2fe494edeb7408deafb29db03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1787145 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "similarity = []\n",
    "indexes = []\n",
    "for idx in tqdm(wv_embeddings.index_to_key):\n",
    "    idx_emb = wv_embeddings[idx]\n",
    "    similarity.append(cosine_sim(idx_emb, wv_embeddings['dog']))\n",
    "    indexes.append(idx)\n",
    "df = pd.DataFrame(\n",
    "    similarity,\n",
    "    index=indexes,\n",
    "    columns=['similarity']).sort_values(by='similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('similarity_dog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('similarity_dog.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dog</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>animal</td>\n",
       "      <td>0.856418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dogs</td>\n",
       "      <td>0.788087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mammal</td>\n",
       "      <td>0.762381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cats</td>\n",
       "      <td>0.762125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>animals</td>\n",
       "      <td>0.760794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0  similarity\n",
       "0        dog    1.000000\n",
       "1     animal    0.856418\n",
       "2       dogs    0.788087\n",
       "3     mammal    0.762381\n",
       "4       cats    0.762125\n",
       "5    animals    0.760794"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ответ 1:</b> Слово cat не входит в top-5 близких к слову dog, но в данный топ входит слово cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-vet', 0.7583354711532593),\n",
       " ('dog', 0.6852341890335083),\n",
       " ('/proc/version', 0.6815888285636902),\n",
       " ('feline', 0.6779966950416565),\n",
       " ('nyan', 0.6685197353363037),\n",
       " ('com/schemas/2007/categories', 0.6678528189659119),\n",
       " ('-et', 0.6623897552490234),\n",
       " ('pajamas', 0.6485012173652649),\n",
       " ('tabby', 0.6465495824813843),\n",
       " ('catcowcat', 0.64402836561203)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv_embeddings.most_similar('cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### С другой стороны в top-5 близких к слову cat входит слово dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ai48-5vv6j1d"
   },
   "source": [
    "### Векторные представления текста\n",
    "\n",
    "Перейдем от векторных представлений отдельных слов к векторным представлениям вопросов, как к **среднему** векторов всех слов в вопросе. Если для какого-то слова нет предобученного вектора, мы его пропустим. Если вопрос не содержит ни одного известного слова, то вернем нулевой вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EhNuxBJd6j1f"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class MyTokenizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def tokenize(self, text):\n",
    "        return re.findall('\\w+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MyTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YHcvu6186j1m"
   },
   "outputs": [],
   "source": [
    "def question_to_vec(question, embeddings, tokenizer, dim=200):\n",
    "    \"\"\"\n",
    "        question: строка\n",
    "        embeddings: наше векторное представление\n",
    "        dim: размер любого вектора в нашем представлении\n",
    "        \n",
    "        return: векторное представление для вопроса\n",
    "    \"\"\"\n",
    "    \n",
    "    question = tokenizer.tokenize(question) #\n",
    "    \n",
    "    question_vectors = []\n",
    "    for word in question:\n",
    "        if word in embeddings:\n",
    "            question_vectors.append(embeddings[word])\n",
    "        else:\n",
    "            question_vectors.append(np.zeros(dim))\n",
    "    if question_vectors == []:\n",
    "        return np.zeros(dim)\n",
    "    question_vectors = np.array(question_vectors).mean(axis=0)\n",
    "    return question_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5Q_4j7r6j1u"
   },
   "source": [
    "Теперь у нас есть метод для создания векторного представления любого предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsJSNkhm6j1y"
   },
   "source": [
    "#### Вопрос 2:\n",
    "* Какая третья(с индексом 2) компонента вектора предложения `I love neural networks`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "a62r11cT6j10",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.96"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(question_to_vec('I love neural networks', wv_embeddings, tokenizer)[2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ответ 2:</b> -0,96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y60z4t6W6j16"
   },
   "source": [
    "### Оценка близости текстов\n",
    "\n",
    "Представим, что мы используем идеальные векторные представления слов. Тогда косинусное расстояние между дублирующими предложениями должно быть меньше, чем между случайно взятыми предложениями. \n",
    "\n",
    "Сгенерируем для каждого из $N$ вопросов $R$ случайных отрицательных примеров и примешаем к ним также настоящие дубликаты. Для каждого вопроса будем ранжировать с помощью нашей модели $R + 1$ примеров и смотреть на позицию дубликата. Мы хотим, чтобы дубликат был первым в ранжированном списке.\n",
    "\n",
    "#### Hits@K\n",
    "Первой простой метрикой будет количество корректных попаданий для какого-то $K$:\n",
    "$$ \\text{Hits@K} = \\frac{1}{N}\\sum_{i=1}^N \\, [rank\\_q_i^{'} \\le K],$$\n",
    "* $\\begin{equation*}\n",
    "[x < 0 ] \\equiv \n",
    " \\begin{cases}\n",
    "   1, &x < 0\\\\\n",
    "   0, &x \\geq 0\n",
    " \\end{cases}\n",
    "\\end{equation*}$ - индикаторная функция\n",
    "* $q_i$ - $i$-ый вопрос\n",
    "* $q_i^{'}$ - его дубликат\n",
    "* $rank\\_q_i^{'}$ - позиция дубликата в ранжированном списке ближайших предложений для вопроса $q_i$.\n",
    "\n",
    "#### DCG@K\n",
    "Второй метрикой будет упрощенная DCG метрика, учитывающая порядок элементов в списке путем домножения релевантности элемента на вес равный обратному логарифму номера позиции::\n",
    "$$ \\text{DCG@K} = \\frac{1}{N} \\sum_{i=1}^N\\frac{1}{\\log_2(1+rank\\_q_i^{'})}\\cdot[rank\\_q_i^{'} \\le K],$$\n",
    "С такой метрикой модель штрафуется за большой ранк корректного ответа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHCnH-jw6j18"
   },
   "source": [
    "#### Вопрос 3:\n",
    "* Максимум `Hits@47 - DCG@1`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ответ 3:</b> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tFemBkP6j1-"
   },
   "source": [
    "<img src='https://hsto.org/files/1c5/edf/dee/1c5edfdeebce4b71a86bdf986d9f88f2.jpg' width=400, height=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0sUSxk866j1_"
   },
   "source": [
    "#### Пример оценок\n",
    "\n",
    "Вычислим описанные выше метрики для игрушечного примера. \n",
    "Пусть\n",
    "* $N = 1$, $R = 3$\n",
    "* <font color='green'>\"Что такое python?\"</font> - вопрос $q_1$\n",
    "* <font color='red'>\"Что такое язык python?\"</font> - его дубликат $q_i^{'}$\n",
    "\n",
    "Пусть модель выдала следующий ранжированный список кандидатов:\n",
    "\n",
    "1. \"Как изучить с++?\"\n",
    "2. <font color='red'>\"Что такое язык python?\"</font>\n",
    "3. \"Хочу учить Java\"\n",
    "4. \"Не понимаю Tensorflow\"\n",
    "\n",
    "$\\Rightarrow rank\\_q_i^{'} = 2$\n",
    "\n",
    "Вычислим метрику *Hits@K* для *K = 1, 4*:\n",
    "\n",
    "- [K = 1] $\\text{Hits@1} =  [rank\\_q_i^{'} \\le 1)] = 0$\n",
    "- [K = 4] $\\text{Hits@4} =  [rank\\_q_i^{'} \\le 4] = 1$\n",
    "\n",
    "Вычислим метрику *DCG@K* для *K = 1, 4*:\n",
    "- [K = 1] $\\text{DCG@1} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 1] = 0$\n",
    "- [K = 4] $\\text{DCG@4} = \\frac{1}{\\log_2(1+2)}\\cdot[2 \\le 4] = \\frac{1}{\\log_2{3}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4L6HJJC6j2B"
   },
   "source": [
    "#### Вопрос 4:\n",
    "* Вычислим `DCG@10`, если $rank\\_q_i^{'} = 9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(1/np.log2(1 + 9) * 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ответ 4:</b> 0,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5xWOORI6j2F"
   },
   "source": [
    "### HITS\\_COUNT и DCG\\_SCORE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I1q9WQOx6j2H"
   },
   "source": [
    "Каждая функция имеет два аргумента: $dup\\_ranks$ и $k$. $dup\\_ranks$ является списком, который содержит рейтинги дубликатов(их позиции в ранжированном списке). Например, $dup\\_ranks = [2]$ для примера, описанного выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "F5VwySUB6j2J"
   },
   "outputs": [],
   "source": [
    "def hits_count(dup_ranks, k):\n",
    "    \"\"\"\n",
    "        dup_ranks: list индексов дубликатов\n",
    "        result: вернуть  Hits@k\n",
    "    \"\"\"\n",
    "    hits_value = np.mean([rank <= k for rank in dup_ranks])\n",
    "    return hits_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "82hQaxCH6j2R"
   },
   "outputs": [],
   "source": [
    "def dcg_score(dup_ranks, k):\n",
    "    \"\"\"\n",
    "        dup_ranks: list индексов дубликатов\n",
    "        result: вернуть DCG@k\n",
    "    \"\"\"\n",
    "    dcg_value = np.mean([(rank <= k) / np.log2(1 + rank) for rank in dup_ranks])\n",
    "    return dcg_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PcwHeXN26j2Y"
   },
   "source": [
    "Протестируем функции. Пусть $N = 1$, то есть один эксперимент. Будем искать копию вопроса и оценивать метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "gLa_Wqfh6j2m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наш ответ HIT: [0.0, 1.0, 1.0, 1.0]\n",
      "Наш ответ DCG: [0.0, 0.63093, 0.63093, 0.63093]\n"
     ]
    }
   ],
   "source": [
    "copy_answers = [\"How does the catch keyword determine the type of exception that was thrown\",]\n",
    "\n",
    "# наши кандидаты\n",
    "candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\",\n",
    "                       \"How does the catch keyword determine the type of exception that was thrown\",\n",
    "                       \"NSLog array description not memory address\",\n",
    "                       \"PECL_HTTP not recognised php ubuntu\"],]\n",
    "# dup_ranks — позиции наших копий, так как эксперимент один, то этот массив длины 1\n",
    "dup_ranks = [2]\n",
    "\n",
    "# вычисляем метрику для разных k\n",
    "print('Наш ответ HIT:', [hits_count(dup_ranks, k) for k in range(1, 5)])\n",
    "print('Наш ответ DCG:', [round(dcg_score(dup_ranks, k), 5) for k in range(1, 5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoHC3YoQ6j2t"
   },
   "source": [
    "У нас должно получиться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "B0NFWq4f6j2u",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HITS</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCG</th>\n",
       "      <td>0</td>\n",
       "      <td>0.63093</td>\n",
       "      <td>0.63093</td>\n",
       "      <td>0.63093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      1        2        3        4\n",
       "HITS  0  1.00000  1.00000  1.00000\n",
       "DCG   0  0.63093  0.63093  0.63093"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# correct_answers - метрика для разных k\n",
    "correct_answers = pd.DataFrame([[0, 1, 1, 1], [0, 1 / (np.log2(3)), 1 / (np.log2(3)), 1 / (np.log2(3))]],\n",
    "                               index=['HITS', 'DCG'], columns=range(1,5))\n",
    "correct_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHZqgDTo6j0i"
   },
   "source": [
    "### Данные\n",
    "[arxiv link](https://drive.google.com/file/d/1QqT4D0EoqJTy7v9VrNCYD-m964XZFR7_/edit)\n",
    "\n",
    "`train.tsv` - выборка для обучения.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>**\n",
    "\n",
    "`validation.tsv` - тестовая выборка.<br> В каждой строке через табуляцию записаны: **<вопрос>, <похожий вопрос>, <отрицательный пример 1>, <отрицательный пример 2>, ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://drive.google.com/file/d/1QqT4D0EoqJTy7v9VrNCYD-m964XZFR7_/edit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1628256058346,
     "user": {
      "displayName": "Deep Learning School",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhNf0RkP5WvkU5MixKfC1Sv3mb-9QWgAbC6VcfQvA=s64",
      "userId": "16549096980415837553"
     },
     "user_tz": -180
    },
    "id": "jKVK2lDGvrIe",
    "outputId": "51944c9b-d6e8-41af-bec4-bb35fba5d51b"
   },
   "outputs": [],
   "source": [
    "# !unzip stackoverflow_similar_questions.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hil2UsUG6j22"
   },
   "source": [
    "Считаем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "B4EBho8s6j26"
   },
   "outputs": [],
   "source": [
    "def read_corpus(filename):\n",
    "    data = []\n",
    "    for line in open(filename, encoding='utf-8'):\n",
    "        data.append(line.strip().split('\\t'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkTxY3Mk9_nG"
   },
   "source": [
    "Нам понадобиться только файл validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "error",
     "timestamp": 1628256058355,
     "user": {
      "displayName": "Deep Learning School",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhNf0RkP5WvkU5MixKfC1Sv3mb-9QWgAbC6VcfQvA=s64",
      "userId": "16549096980415837553"
     },
     "user_tz": -180
    },
    "id": "PTVB9Tnp6j29",
    "outputId": "9c55c802-3d82-471d-eab2-195dabf5026c"
   },
   "outputs": [],
   "source": [
    "validation_data = read_corpus('./data/validation.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTHfL-9y6j3F"
   },
   "source": [
    "Кол-во строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "z6ubXhIe6j3H"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3760"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kaOQblBy6j3M"
   },
   "source": [
    "Размер нескольких первых строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "yRx6e-Pe6j3M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1001\n",
      "2 1001\n",
      "3 1001\n",
      "4 1001\n",
      "5 1001\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i + 1, len(validation_data[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySQQp0oQt1Ep"
   },
   "source": [
    "### Ранжирование без обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iElEDhj-6j3R"
   },
   "source": [
    "Реализуем функцию ранжирования кандидатов на основе косинусного расстояния. Функция должна по списку кандидатов вернуть отсортированный список пар (позиция в исходном списке кандидатов, кандидат). При этом позиция кандидата в полученном списке является его рейтингом (первый - лучший). Например, если исходный список кандидатов был [a, b, c], и самый похожий на исходный вопрос среди них - c, затем a, и в конце b, то функция должна вернуть список\n",
    "\n",
    "**[(2, c), (0, a), (1, b)]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "K02JARKr6j3T"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "1yP8wJWj6j3X"
   },
   "outputs": [],
   "source": [
    "def rank_candidates(question, candidates, embeddings, tokenizer, dim=200):\n",
    "    \"\"\"\n",
    "        question: строка\n",
    "        candidates: массив строк(кандидатов) [a, b, c]\n",
    "        result: пары (начальная позиция, кандидат) [(2, c), (0, a), (1, b)]\n",
    "    \"\"\"\n",
    "    question_is_vec = question_to_vec(question, embeddings, tokenizer, dim)\n",
    "    candidate_is_vecs = [question_to_vec(candidate, embeddings, tokenizer, dim)\n",
    "                      for candidate in candidates]\n",
    "    cosine_similarities = [\n",
    "        (\n",
    "            i,\n",
    "            candidates[i],\n",
    "            cosine_similarity(\n",
    "                candidate.reshape(1, -1), question_is_vec.reshape(1, -1)\n",
    "            )[0]\n",
    "        ) \n",
    "        for i, candidate in enumerate(candidate_is_vecs)\n",
    "    ]\n",
    "    cosine_similarities.sort(key=lambda x: x[2], reverse=True)\n",
    "    return [(i[0], i[1]) for i in cosine_similarities]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TnBszTb76j3c"
   },
   "source": [
    "Протестируем работу функции на примерах ниже. Пусть $N=2$, то есть два эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "xvQgtP176j3h"
   },
   "outputs": [],
   "source": [
    "questions = ['converting string to list', 'Sending array via Ajax fails'] \n",
    "\n",
    "candidates = [['Convert Google results object (pure js) to Python object', # первый эксперимент\n",
    "               'C# create cookie from string and send it',\n",
    "               'How to use jQuery AJAX for an outside domain?'],\n",
    "              \n",
    "              ['Getting all list items of an unordered list in PHP',      # второй эксперимент\n",
    "               'WPF- How to update the changes in list item of a list',\n",
    "               'select2 not displaying search results']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "bPj1JGFi6j3m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting string to list\n",
      "(1, 'C# create cookie from string and send it')\n",
      "(0, 'Convert Google results object (pure js) to Python object')\n",
      "(2, 'How to use jQuery AJAX for an outside domain?')\n",
      "\n",
      "Sending array via Ajax fails\n",
      "(1, 'WPF- How to update the changes in list item of a list')\n",
      "(0, 'Getting all list items of an unordered list in PHP')\n",
      "(2, 'select2 not displaying search results')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question, q_candidates in zip(questions, candidates):\n",
    "        ranks = rank_candidates(question, q_candidates, wv_embeddings, tokenizer)\n",
    "        print(question)\n",
    "        print(*ranks, sep='\\n')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jm4cidj56j3q"
   },
   "source": [
    "Для первого экперимента мы можем полностью сравнить наши ответы и правильные ответы. Но для второго эксперимента два ответа на кандидаты будут <b>скрыты</b>(*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "0LeKMIsn6j3s"
   },
   "outputs": [],
   "source": [
    "# должно вывести\n",
    "results = [[(1, 'C# create cookie from string and send it'),\n",
    "            (0, 'Convert Google results object (pure js) to Python object'),\n",
    "            (2, 'How to use jQuery AJAX for an outside domain?')],\n",
    "           [(*, 'Getting all list items of an unordered list in PHP'), #скрыт\n",
    "            (*, 'select2 not displaying search results'), #скрыт\n",
    "            (*, 'WPF- How to update the changes in list item of a list')]] #скрыт"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1ttnIBe6j3x"
   },
   "source": [
    "Последовательность начальных индексов мы должны получить `для эксперимента 1`  1, 0, 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5WQgYDWd6j3y"
   },
   "source": [
    "#### Вопрос 5:\n",
    "* Какую последовательность начальных индексов мы получим `для эксперимента 2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ответ 5:</b> 102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fPllOY-Y6j30"
   },
   "source": [
    "Теперь мы можем оценить качество нашего метода. Запустим следующие два блока кода для получения результата. Обратите внимание, что вычисление расстояния между векторами занимает некоторое время (примерно 10 минут). Возьмем для validation 1000 примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Z3q9sxddz-yU"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "nu7K4mis6j32"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e518610c314f7083463e5aa23131b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wv_ranking = []\n",
    "max_validation_examples = 1000\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, wv_embeddings, tokenizer)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wv_ranking', 'wb') as fp:\n",
    "    pickle.dump(wv_ranking, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('wv_ranking', 'rb') as fp:\n",
    "    wv_ranking = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "gDtS520v6j35",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8998e190167e4d25bb128ae10ecc9757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.285 | Hits@   1: 0.285\n",
      "DCG@   5: 0.342 | Hits@   5: 0.393\n",
      "DCG@  10: 0.360 | Hits@  10: 0.449\n",
      "DCG@ 100: 0.406 | Hits@ 100: 0.679\n",
      "DCG@ 500: 0.431 | Hits@ 500: 0.879\n",
      "DCG@1000: 0.444 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LL6_Rjg3InL8"
   },
   "source": [
    "### Эмбеддинги, обученные на корпусе похожих вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "iNvbpR5gJIPz"
   },
   "outputs": [],
   "source": [
    "train_data = read_corpus('./data/train.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nr281ZyEJfjT"
   },
   "source": [
    "Улучшим качество модели.<br>Склеим вопросы в пары и обучим на них модель Word2Vec из gensim. Выберем размер window равный 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['converting string to list',\n",
       " 'Convert Google results object (pure js) to Python object']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_data = set()\n",
    "for i in train_data:\n",
    "    len_data.add(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 32,\n",
       " 39,\n",
       " 40,\n",
       " 43,\n",
       " 46,\n",
       " 95}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518a02f9ae5d424ab04bfb7589c92049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = []\n",
    "for questions in tqdm(train_data):\n",
    "    temp = []\n",
    "    for question in questions:\n",
    "        temp.append(tokenizer.tokenize(question))\n",
    "    words.append([c for i in temp for c in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "f6Y46SSQMTL0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['converting',\n",
       " 'string',\n",
       " 'to',\n",
       " 'list',\n",
       " 'Convert',\n",
       " 'Google',\n",
       " 'results',\n",
       " 'object',\n",
       " 'pure',\n",
       " 'js',\n",
       " 'to',\n",
       " 'Python',\n",
       " 'object']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "QuJzAM0cI-UH"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "embeddings_trained = Word2Vec(words,      # data for model to train on\n",
    "                 vector_size=200,                # embedding vector size\n",
    "                 min_count=3,             # consider words that occured at least 5 times\n",
    "                 window=3).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.14655508,  0.13401586,  1.2812852 , -0.3862412 , -1.4931382 ,\n",
       "       -0.23512991,  0.52709836, -1.0516547 , -1.618552  , -0.6120148 ,\n",
       "        1.1346965 ,  0.84530836, -1.3533063 ,  0.9493681 , -1.1706654 ,\n",
       "        0.96381897,  0.13132158,  0.89281034, -0.72785264, -0.07059141,\n",
       "       -0.83882105, -0.21950379,  0.82545054, -0.03775861,  1.0543708 ,\n",
       "       -0.04066826,  0.3331035 , -0.69339186,  0.20062669, -1.4839451 ,\n",
       "        1.0667356 ,  2.9003057 ,  0.992881  , -0.79530877,  1.9275753 ,\n",
       "       -1.7454611 ,  1.2166214 , -0.52379334,  0.10875949, -1.4206609 ,\n",
       "       -1.9432591 , -0.09787348, -0.5528832 , -1.0307075 , -0.3877822 ,\n",
       "        1.3026282 ,  1.2682195 ,  0.2791199 ,  0.04734347,  0.22586524,\n",
       "       -1.1170361 ,  0.43883163, -0.35316446,  0.46305734,  0.53634876,\n",
       "        1.1462197 , -0.25928244,  0.46222493,  0.64302474,  2.8942978 ,\n",
       "        1.3424782 ,  0.20278509, -0.719558  , -1.3980956 ,  0.21107996,\n",
       "       -0.95744675, -2.0081391 , -0.1335252 , -0.30521867, -0.8557758 ,\n",
       "        0.7320497 , -0.01891887, -0.07143671,  0.45683387,  0.4181906 ,\n",
       "       -1.4871414 ,  0.10740583,  1.4464645 ,  1.5428675 ,  1.8860345 ,\n",
       "        0.28757626,  1.1597509 , -1.0817904 , -1.4493902 , -0.4725657 ,\n",
       "        0.87283367, -0.19846311, -0.33812928,  0.42108545, -0.97456986,\n",
       "       -0.13392372, -2.170091  , -0.32421488, -1.7216694 , -2.0286908 ,\n",
       "       -1.0027435 , -0.74085736, -1.3467087 ,  0.17010555, -0.96855384,\n",
       "       -0.35128012,  0.08111612, -0.09520765,  0.8338803 , -0.8685847 ,\n",
       "        1.1613023 , -1.4840732 ,  0.80490637, -0.0403465 ,  0.85390216,\n",
       "        1.0153456 ,  0.813046  ,  0.5172056 ,  1.2731621 , -1.2006452 ,\n",
       "        1.8500773 ,  0.27428252,  2.9596033 , -0.19679458, -1.0851909 ,\n",
       "       -0.7793547 , -0.29094893, -0.46126068, -1.0295123 , -0.7157686 ,\n",
       "       -0.3630694 , -1.5431533 , -0.49378502,  0.48794508,  0.8864636 ,\n",
       "       -0.3465005 , -0.4249986 ,  1.348918  , -0.8614331 ,  0.5833375 ,\n",
       "        1.0970241 , -0.01417416,  0.04914194,  1.7686741 , -0.15501857,\n",
       "       -0.1413166 , -0.00618274,  0.07505386,  0.27328777, -0.23807926,\n",
       "       -0.5567095 , -0.7564991 ,  0.28914374,  1.6261352 , -0.5864621 ,\n",
       "        0.07884547, -0.52467865, -0.45785627, -0.410399  , -0.10767674,\n",
       "       -1.5280554 ,  0.6373083 , -0.574744  ,  0.75825596, -2.1867926 ,\n",
       "       -0.9692066 ,  0.20521995,  0.5923414 , -0.11386704,  0.3693409 ,\n",
       "        1.3189355 ,  0.8356514 ,  0.8147433 ,  0.13824391, -1.052801  ,\n",
       "       -0.2080754 , -2.0016723 , -0.903225  ,  0.7876482 , -0.17473637,\n",
       "       -0.54605895, -0.50446457,  0.9001207 ,  0.3087413 , -0.5102197 ,\n",
       "        1.9354709 ,  0.79439586,  2.1406474 , -0.68315023,  0.03102631,\n",
       "       -1.9975069 , -0.75771946, -0.18602467, -0.694922  ,  0.79382306,\n",
       "       -0.5103254 ,  1.2020168 ,  0.8969265 ,  1.4596192 , -1.0297815 ,\n",
       "       -0.57828027, -1.2829965 , -0.56252253, -0.5482053 , -1.3334075 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_trained[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "OQonbm4nMenD"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbe76244ddb43f5aa4a045e61ecb35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wv_ranking = []\n",
    "max_validation_examples = 1000\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, embeddings_trained, tokenizer)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "3kahBUPGMgGR",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e1bb68016146769f63bbbdd44b6da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.253 | Hits@   1: 0.253\n",
      "DCG@   5: 0.312 | Hits@   5: 0.367\n",
      "DCG@  10: 0.337 | Hits@  10: 0.446\n",
      "DCG@ 100: 0.388 | Hits@ 100: 0.696\n",
      "DCG@ 500: 0.415 | Hits@ 500: 0.912\n",
      "DCG@1000: 0.425 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем удалить стоп-слова и лемматизировать текст перед этим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stopWords = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "for questions in tqdm(train_data):\n",
    "    for question in questions:\n",
    "        temp = []\n",
    "        temp.append(' '.join(\n",
    "            [wnl.lemmatize(word) for word in word_tokenize(question) if word not in stopWords]\n",
    "        ))\n",
    "    words.append([c for i in temp for c in i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_trained = Word2Vec(words,      # data for model to train on\n",
    "                 vector_size=200,                # embedding vector size\n",
    "                 min_count=3,             # consider words that occured at least 5 times\n",
    "                 window=3).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41deb56b96f84f34a731317aaba1a0c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wv_ranking = []\n",
    "max_validation_examples = 1000\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, embeddings_trained, tokenizer)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a20d837eaf4f498d10b57bb40d9b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.237 | Hits@   1: 0.237\n",
      "DCG@   5: 0.295 | Hits@   5: 0.348\n",
      "DCG@  10: 0.317 | Hits@  10: 0.418\n",
      "DCG@ 100: 0.372 | Hits@ 100: 0.693\n",
      "DCG@ 500: 0.401 | Hits@ 500: 0.913\n",
      "DCG@1000: 0.410 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем удалить стоп-слова и не лемматизировать текст перед этим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc_words = [tokenizer.tokenize(' '.join(data).lower()) \n",
    "                 for data in train_data]\n",
    "words = [[word for word in row if word not in stopWords] \n",
    "         for row in preproc_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_trained = Word2Vec(words,      # data for model to train on\n",
    "                 vector_size=200,                # embedding vector size\n",
    "                 min_count=5,             # consider words that occured at least 5 times\n",
    "                 window=20).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "708c7d2f0e4043a8b425b873edbd46b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wv_ranking = []\n",
    "max_validation_examples = 1000\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, embeddings_trained, tokenizer)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b42aa7fad64789ae32dfc61ae961d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.284 | Hits@   1: 0.284\n",
      "DCG@   5: 0.352 | Hits@   5: 0.414\n",
      "DCG@  10: 0.372 | Hits@  10: 0.473\n",
      "DCG@ 100: 0.416 | Hits@ 100: 0.690\n",
      "DCG@ 500: 0.438 | Hits@ 500: 0.866\n",
      "DCG@1000: 0.452 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем свой кастомный токенайзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stopWords = set(stopwords.words('english'))\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenizer:\n",
    "    def tokenize(self, text):\n",
    "        text = re.sub(f'[{string.punctuation}]', ' ', text)\n",
    "        return [wnl.lemmatize(word) for word in tokenizer.tokenize(text.lower()) if word not in stopWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh',\n",
       " 'think',\n",
       " 'landed',\n",
       " 'miracle',\n",
       " 'work',\n",
       " 'thirst',\n",
       " 'hunger',\n",
       " 'come',\n",
       " 'conference',\n",
       " 'bird']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = \"Oh, I think I ve landed Where there are miracles at work,  For the thirst and for the hunger Come the conference of birds\"\n",
    "custom_tokenizer = CustomTokenizer()\n",
    "custom_tokenizer.tokenize(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68c3d796f1e431cac0886749cffbb7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = []\n",
    "for pair in tqdm(train_data):\n",
    "    for sent in pair:\n",
    "        words.append(custom_tokenizer.tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_trained = Word2Vec(words, # data for model to train on\n",
    "                 vector_size=200,                 # embedding vector size\n",
    "                 min_count=7,             # consider words that occured at least 5 times\n",
    "                 window=3).wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc69e7e97ec8458db70e0d14414531f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3760 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wv_ranking = []\n",
    "max_validation_examples = 1000\n",
    "for i, line in enumerate(tqdm(validation_data)):\n",
    "    if i == max_validation_examples:\n",
    "        break\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, embeddings_trained, custom_tokenizer)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d8ae74c434428194ba193030f3e760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DCG@   1: 0.396 | Hits@   1: 0.396\n",
      "DCG@   5: 0.487 | Hits@   5: 0.566\n",
      "DCG@  10: 0.511 | Hits@  10: 0.640\n",
      "DCG@ 100: 0.558 | Hits@ 100: 0.867\n",
      "DCG@ 500: 0.572 | Hits@ 500: 0.974\n",
      "DCG@1000: 0.575 | Hits@1000: 1.000\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm([1, 5, 10, 100, 500, 1000]):\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С кастомным токенайзером выглядит лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tY8PxB0j-ThG"
   },
   "source": [
    "### Выводы о полученных результатах:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emODHztAQUQz"
   },
   "source": [
    "* C кастомным токенайзаром результат намного лучше\n",
    "* Нормализация слов помогает в улучшении качества\n",
    "* Самостоятельно обученные эмбеддинги лучше справились с задачей\n",
    "* Из-за простоты попробованных методов у нас получиличь не самые лучшие решения"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "BIWqBuEa6j0b",
    "uS9FwWNd5a3S",
    "MQk_rolFwT_h",
    "ai48-5vv6j1d",
    "Y60z4t6W6j16",
    "0sUSxk866j1_",
    "J5xWOORI6j2F",
    "tHZqgDTo6j0i",
    "ySQQp0oQt1Ep",
    "LL6_Rjg3InL8"
   ],
   "name": "[homework]simple_embeddings.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env_kernel",
   "language": "python",
   "name": "env_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
